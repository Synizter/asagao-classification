{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import normalize\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = []\n",
    "msk_dataset = []\n",
    "\n",
    "f_img = sorted(glob('dataset/train/asagao/*'))\n",
    "for f in f_img:\n",
    "    image = cv2.imread(f)\n",
    "    # image = image.resize((SIZE, SIZE))\n",
    "    #Nomalize an image from 0-255 to 0 - 1\n",
    "    image = image.astype('float32') / 255.0\n",
    "    img_dataset.append(np.array(image))\n",
    "\n",
    "f_msk = sorted(glob('dataset/validation/asagao/*'))\n",
    "for f in f_msk:\n",
    "    image = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "    (thresh, im_bw) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    image = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # image = Image.fromarray(image)\n",
    "    # image = image.resize((SIZE, SIZE))\n",
    "    msk_dataset.append(np.array(image))\n",
    "asagao_dataset = np.array(img_dataset)\n",
    "asagao_msk_dataset = np.expand_dims(np.array(msk_dataset) /255., -1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X_train, X_test, y_train, y_test = train_test_split(asagao_dataset, asagao_msk_dataset, test_size= 0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with asagao pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_previous = history\n",
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    verbose = 1,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 100,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    shuffle = False)\n",
    "model.save(\"50m_30m_Unet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = history_previous\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training acc',linewidth=2)\n",
    "plt.plot(epochs, val_acc, 'r--', label='Validation acc',linewidth=2)\n",
    "plt.title('Training  accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "\n",
    "plt.plot(epochs, val_loss, 'k', label='Validationloss ')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.6\n",
    "\n",
    "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
    "union = np.logical_or(y_test, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test within known data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tile(tile, sens = 0.001):\n",
    "    tile = tile.astype('float32') / 255.0\n",
    "    test_img_other_input=np.expand_dims(tile, 0)\n",
    "    prob_map = (model.predict(test_img_other_input) > sensitivty).astype(np.uint8)\n",
    "    return prob_map[0]\n",
    "    \n",
    "\n",
    "# file_name = \"asagao_0001.png\"\n",
    "# train_file = 'dataset/train/asagao/' + file_name\n",
    "# test_file = 'dataset/validation/asagao/' + file_name.replace(\"asagao_\", \"asagao_mask_\" )\n",
    "\n",
    "# print(train_file, test_file)\n",
    "# sensitivty = 0.4\n",
    "# test_img_other = cv2.imread(train_file)\n",
    "# r = predict_tile(test_img_other, sensitivty)\n",
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# actual = cv2.imread(train_file)\n",
    "# mask = cv2.imread(test_file)\n",
    "# plt.subplot(131),plt.imshow(actual),plt.title(\"Actual\")\n",
    "# plt.subplot(132),plt.imshow(mask),plt.title(\"Actual mask\")\n",
    "# plt.subplot(133),plt.imshow(r, cmap=\"gray\"),plt.title(\"Prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with tiled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-28 15:43:22.601509: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-28 15:43:22.608794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-28 15:43:23.079490: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:23.079815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 34 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-01-28 15:43:23.080371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-28 15:43:23.084938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-28 15:43:23.085049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-28 15:43:23.103082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-28 15:43:23.106254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-28 15:43:23.111679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-28 15:43:23.114719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-28 15:43:23.123449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-28 15:43:23.124132: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:23.124525: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:23.124542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-28 15:43:23.125017: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-28 15:43:23.126667: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:23.126702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 34 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-01-28 15:43:23.126727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-28 15:43:23.126756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-28 15:43:23.126768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-28 15:43:23.126779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-28 15:43:23.126805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-28 15:43:23.126826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-28 15:43:23.126837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-28 15:43:23.126847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-28 15:43:23.127196: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:23.127548: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:23.127564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-28 15:43:23.128168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-28 15:43:24.762930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-28 15:43:24.762965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-28 15:43:24.762971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-28 15:43:24.763974: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:24.763995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1489] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-01-28 15:43:24.764320: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:24.764644: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:927] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-28 15:43:24.764682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6616 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5)\n",
      "2022-01-28 15:43:24.766268: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('50m_30mUnet_All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found previous tiled images, attemp delete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 17:51:25.646701: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-26 17:51:25.647898: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3393720000 Hz\n",
      "2022-01-26 17:51:25.936932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-26 17:51:28.230240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted dataset/test/test1/Tile_0001.png in 3.52981687 s\n",
      "predicted dataset/test/test1/Tile_0002.png in 0.04249310 s\n",
      "predicted dataset/test/test1/Tile_0003.png in 0.03827882 s\n",
      "predicted dataset/test/test1/Tile_0004.png in 0.03385162 s\n",
      "predicted dataset/test/test1/Tile_0005.png in 0.03514290 s\n",
      "predicted dataset/test/test1/Tile_0006.png in 0.03792357 s\n",
      "predicted dataset/test/test1/Tile_0007.png in 0.03868127 s\n",
      "predicted dataset/test/test1/Tile_0008.png in 0.04328418 s\n",
      "predicted dataset/test/test1/Tile_0009.png in 0.04036856 s\n",
      "predicted dataset/test/test1/Tile_0010.png in 0.03719616 s\n",
      "predicted dataset/test/test1/Tile_0011.png in 0.06281209 s\n",
      "predicted dataset/test/test1/Tile_0012.png in 0.04533529 s\n",
      "predicted dataset/test/test1/Tile_0013.png in 0.03436184 s\n",
      "predicted dataset/test/test1/Tile_0014.png in 0.03841114 s\n",
      "predicted dataset/test/test1/Tile_0015.png in 0.03308964 s\n",
      "predicted dataset/test/test1/Tile_0016.png in 0.03525710 s\n",
      "predicted dataset/test/test1/Tile_0017.png in 0.03410935 s\n",
      "predicted dataset/test/test1/Tile_0018.png in 0.03529000 s\n",
      "predicted dataset/test/test1/Tile_0019.png in 0.03261399 s\n",
      "predicted dataset/test/test1/Tile_0020.png in 0.03273225 s\n",
      "predicted dataset/test/test1/Tile_0021.png in 0.03853607 s\n",
      "predicted dataset/test/test1/Tile_0022.png in 0.03871059 s\n",
      "predicted dataset/test/test1/Tile_0023.png in 0.04313540 s\n",
      "predicted dataset/test/test1/Tile_0024.png in 0.03797364 s\n",
      "predicted dataset/test/test1/Tile_0025.png in 0.04284215 s\n",
      "predicted dataset/test/test1/Tile_0026.png in 0.03782105 s\n",
      "predicted dataset/test/test1/Tile_0027.png in 0.03431702 s\n",
      "predicted dataset/test/test1/Tile_0028.png in 0.04091239 s\n",
      "predicted dataset/test/test1/Tile_0029.png in 0.03705835 s\n",
      "predicted dataset/test/test1/Tile_0030.png in 0.04279351 s\n",
      "predicted dataset/test/test1/Tile_0031.png in 0.04110289 s\n",
      "predicted dataset/test/test1/Tile_0032.png in 0.04822350 s\n",
      "predicted dataset/test/test1/Tile_0033.png in 0.04495120 s\n",
      "predicted dataset/test/test1/Tile_0034.png in 0.03228569 s\n",
      "predicted dataset/test/test1/Tile_0035.png in 0.03333211 s\n",
      "predicted dataset/test/test1/Tile_0036.png in 0.04031372 s\n",
      "predicted dataset/test/test1/Tile_0037.png in 0.03239489 s\n",
      "predicted dataset/test/test1/Tile_0038.png in 0.03332424 s\n",
      "predicted dataset/test/test1/Tile_0039.png in 0.03339529 s\n",
      "predicted dataset/test/test1/Tile_0040.png in 0.03707576 s\n",
      "predicted dataset/test/test1/Tile_0041.png in 0.03162980 s\n",
      "predicted dataset/test/test1/Tile_0042.png in 0.03404808 s\n",
      "predicted dataset/test/test1/Tile_0043.png in 0.03286791 s\n",
      "predicted dataset/test/test1/Tile_0044.png in 0.03303099 s\n",
      "predicted dataset/test/test1/Tile_0045.png in 0.03419805 s\n",
      "predicted dataset/test/test1/Tile_0046.png in 0.03862429 s\n",
      "predicted dataset/test/test1/Tile_0047.png in 0.04580832 s\n",
      "predicted dataset/test/test1/Tile_0048.png in 0.03779507 s\n",
      "predicted dataset/test/test1/Tile_0049.png in 0.04283762 s\n",
      "predicted dataset/test/test1/Tile_0050.png in 0.03522635 s\n",
      "predicted dataset/test/test1/Tile_0051.png in 0.03655648 s\n",
      "predicted dataset/test/test1/Tile_0052.png in 0.03717995 s\n",
      "predicted dataset/test/test1/Tile_0053.png in 0.03988957 s\n",
      "predicted dataset/test/test1/Tile_0054.png in 0.03569102 s\n",
      "predicted dataset/test/test1/Tile_0055.png in 0.03953481 s\n",
      "predicted dataset/test/test1/Tile_0056.png in 0.03519154 s\n",
      "predicted dataset/test/test1/Tile_0057.png in 0.03710294 s\n",
      "predicted dataset/test/test1/Tile_0058.png in 0.04260039 s\n",
      "predicted dataset/test/test1/Tile_0059.png in 0.03659821 s\n",
      "predicted dataset/test/test1/Tile_0060.png in 0.03670692 s\n",
      "predicted dataset/test/test1/Tile_0061.png in 0.03548717 s\n",
      "predicted dataset/test/test1/Tile_0062.png in 0.03432560 s\n",
      "predicted dataset/test/test1/Tile_0063.png in 0.03696680 s\n",
      "predicted dataset/test/test1/Tile_0064.png in 0.03599262 s\n",
      "predicted dataset/test/test1/Tile_0065.png in 0.03624296 s\n",
      "predicted dataset/test/test1/Tile_0066.png in 0.04095411 s\n",
      "predicted dataset/test/test1/Tile_0067.png in 0.03659964 s\n",
      "predicted dataset/test/test1/Tile_0068.png in 0.03554416 s\n",
      "predicted dataset/test/test1/Tile_0069.png in 0.03626013 s\n",
      "predicted dataset/test/test1/Tile_0070.png in 0.03703308 s\n",
      "predicted dataset/test/test1/Tile_0071.png in 0.03693271 s\n",
      "predicted dataset/test/test1/Tile_0072.png in 0.03754759 s\n",
      "predicted dataset/test/test1/Tile_0073.png in 0.03715181 s\n",
      "predicted dataset/test/test1/Tile_0074.png in 0.03722143 s\n",
      "predicted dataset/test/test1/Tile_0075.png in 0.04218864 s\n",
      "predicted dataset/test/test1/Tile_0076.png in 0.03620982 s\n",
      "predicted dataset/test/test1/Tile_0077.png in 0.03611708 s\n",
      "predicted dataset/test/test1/Tile_0078.png in 0.03581476 s\n",
      "predicted dataset/test/test1/Tile_0079.png in 0.03623772 s\n",
      "predicted dataset/test/test1/Tile_0080.png in 0.03560090 s\n",
      "predicted dataset/test/test1/Tile_0081.png in 0.04515100 s\n",
      "predicted dataset/test/test1/Tile_0082.png in 0.03854275 s\n",
      "predicted dataset/test/test1/Tile_0083.png in 0.03829312 s\n",
      "predicted dataset/test/test1/Tile_0084.png in 0.04128027 s\n",
      "predicted dataset/test/test1/Tile_0085.png in 0.03840160 s\n",
      "predicted dataset/test/test1/Tile_0086.png in 0.03912902 s\n",
      "predicted dataset/test/test1/Tile_0087.png in 0.03671503 s\n",
      "predicted dataset/test/test1/Tile_0088.png in 0.03661251 s\n",
      "predicted dataset/test/test1/Tile_0089.png in 0.03717041 s\n",
      "predicted dataset/test/test1/Tile_0090.png in 0.04523349 s\n",
      "predicted dataset/test/test1/Tile_0091.png in 0.07250047 s\n",
      "predicted dataset/test/test1/Tile_0092.png in 0.10345125 s\n",
      "predicted dataset/test/test1/Tile_0093.png in 0.05884528 s\n",
      "predicted dataset/test/test1/Tile_0094.png in 0.06283879 s\n",
      "predicted dataset/test/test1/Tile_0095.png in 0.04749513 s\n",
      "predicted dataset/test/test1/Tile_0096.png in 0.04035711 s\n",
      "predicted dataset/test/test1/Tile_0097.png in 0.03947115 s\n",
      "predicted dataset/test/test1/Tile_0098.png in 0.04073381 s\n",
      "predicted dataset/test/test1/Tile_0099.png in 0.03995919 s\n",
      "predicted dataset/test/test1/Tile_0100.png in 0.03992748 s\n",
      "predicted dataset/test/test1/Tile_0101.png in 0.04726458 s\n",
      "predicted dataset/test/test1/Tile_0102.png in 0.04201698 s\n",
      "predicted dataset/test/test1/Tile_0103.png in 0.04144144 s\n",
      "predicted dataset/test/test1/Tile_0104.png in 0.04929590 s\n",
      "predicted dataset/test/test1/Tile_0105.png in 0.04955339 s\n",
      "predicted dataset/test/test1/Tile_0106.png in 0.04684377 s\n",
      "predicted dataset/test/test1/Tile_0107.png in 0.04681540 s\n",
      "predicted dataset/test/test1/Tile_0108.png in 0.04414272 s\n",
      "predicted dataset/test/test1/Tile_0109.png in 0.04889393 s\n",
      "predicted dataset/test/test1/Tile_0110.png in 0.05113196 s\n",
      "predicted dataset/test/test1/Tile_0111.png in 0.04387331 s\n",
      "predicted dataset/test/test1/Tile_0112.png in 0.04575610 s\n",
      "predicted dataset/test/test1/Tile_0113.png in 0.04753518 s\n",
      "predicted dataset/test/test1/Tile_0114.png in 0.04820919 s\n",
      "predicted dataset/test/test1/Tile_0115.png in 0.04546475 s\n",
      "predicted dataset/test/test1/Tile_0116.png in 0.04655790 s\n",
      "predicted dataset/test/test1/Tile_0117.png in 0.04509807 s\n",
      "predicted dataset/test/test1/Tile_0118.png in 0.05015349 s\n",
      "predicted dataset/test/test1/Tile_0119.png in 0.04452848 s\n",
      "predicted dataset/test/test1/Tile_0120.png in 0.04453731 s\n",
      "predicted dataset/test/test1/Tile_0121.png in 0.04282880 s\n",
      "predicted dataset/test/test1/Tile_0122.png in 0.04103136 s\n",
      "predicted dataset/test/test1/Tile_0123.png in 0.04750609 s\n",
      "predicted dataset/test/test1/Tile_0124.png in 0.04207754 s\n",
      "predicted dataset/test/test1/Tile_0125.png in 0.04038835 s\n",
      "predicted dataset/test/test1/Tile_0126.png in 0.04208398 s\n",
      "predicted dataset/test/test1/Tile_0127.png in 0.04967642 s\n",
      "predicted dataset/test/test1/Tile_0128.png in 0.04827213 s\n",
      "predicted dataset/test/test1/Tile_0129.png in 0.04716516 s\n",
      "predicted dataset/test/test1/Tile_0130.png in 0.04120469 s\n",
      "predicted dataset/test/test1/Tile_0131.png in 0.03976846 s\n",
      "predicted dataset/test/test1/Tile_0132.png in 0.04034829 s\n",
      "predicted dataset/test/test1/Tile_0133.png in 0.04150486 s\n",
      "predicted dataset/test/test1/Tile_0134.png in 0.04583216 s\n",
      "predicted dataset/test/test1/Tile_0135.png in 0.04588938 s\n",
      "predicted dataset/test/test1/Tile_0136.png in 0.04497075 s\n",
      "predicted dataset/test/test1/Tile_0137.png in 0.04234552 s\n",
      "predicted dataset/test/test1/Tile_0138.png in 0.04654956 s\n",
      "predicted dataset/test/test1/Tile_0139.png in 0.04034734 s\n",
      "predicted dataset/test/test1/Tile_0140.png in 0.03906584 s\n",
      "predicted dataset/test/test1/Tile_0141.png in 0.04134679 s\n",
      "predicted dataset/test/test1/Tile_0142.png in 0.03924036 s\n",
      "predicted dataset/test/test1/Tile_0143.png in 0.04486966 s\n",
      "predicted dataset/test/test1/Tile_0144.png in 0.04997706 s\n",
      "predicted dataset/test/test1/Tile_0145.png in 0.04653454 s\n",
      "predicted dataset/test/test1/Tile_0146.png in 0.04588532 s\n",
      "predicted dataset/test/test1/Tile_0147.png in 0.04623175 s\n",
      "predicted dataset/test/test1/Tile_0148.png in 0.05134726 s\n",
      "predicted dataset/test/test1/Tile_0149.png in 0.04563522 s\n",
      "predicted dataset/test/test1/Tile_0150.png in 0.04515052 s\n",
      "predicted dataset/test/test1/Tile_0151.png in 0.04469872 s\n",
      "predicted dataset/test/test1/Tile_0152.png in 0.05082941 s\n",
      "predicted dataset/test/test1/Tile_0153.png in 0.04970551 s\n",
      "predicted dataset/test/test1/Tile_0154.png in 0.04582381 s\n",
      "predicted dataset/test/test1/Tile_0155.png in 0.04570985 s\n",
      "predicted dataset/test/test1/Tile_0156.png in 0.04499578 s\n",
      "predicted dataset/test/test1/Tile_0157.png in 0.05079269 s\n",
      "predicted dataset/test/test1/Tile_0158.png in 0.04617357 s\n",
      "predicted dataset/test/test1/Tile_0159.png in 0.05172706 s\n",
      "predicted dataset/test/test1/Tile_0160.png in 0.04593158 s\n",
      "predicted dataset/test/test1/Tile_0161.png in 0.04817009 s\n",
      "predicted dataset/test/test1/Tile_0162.png in 0.05359125 s\n",
      "predicted dataset/test/test1/Tile_0163.png in 0.04608297 s\n",
      "predicted dataset/test/test1/Tile_0164.png in 0.04504776 s\n",
      "predicted dataset/test/test1/Tile_0165.png in 0.04537916 s\n",
      "predicted dataset/test/test1/Tile_0166.png in 0.04891205 s\n",
      "predicted dataset/test/test1/Tile_0167.png in 0.04550600 s\n",
      "predicted dataset/test/test1/Tile_0168.png in 0.04354167 s\n",
      "predicted dataset/test/test1/Tile_0169.png in 0.04316235 s\n",
      "predicted dataset/test/test1/Tile_0170.png in 0.06223750 s\n",
      "predicted dataset/test/test1/Tile_0171.png in 0.04408169 s\n",
      "predicted dataset/test/test1/Tile_0172.png in 0.04534316 s\n",
      "predicted dataset/test/test1/Tile_0173.png in 0.04547977 s\n",
      "predicted dataset/test/test1/Tile_0174.png in 0.04319859 s\n",
      "predicted dataset/test/test1/Tile_0175.png in 0.05522704 s\n",
      "predicted dataset/test/test1/Tile_0176.png in 0.04571342 s\n",
      "predicted dataset/test/test1/Tile_0177.png in 0.04432559 s\n",
      "predicted dataset/test/test1/Tile_0178.png in 0.05338311 s\n",
      "predicted dataset/test/test1/Tile_0179.png in 0.05257487 s\n",
      "predicted dataset/test/test1/Tile_0180.png in 0.06281471 s\n",
      "predicted dataset/test/test1/Tile_0181.png in 0.10921264 s\n",
      "predicted dataset/test/test1/Tile_0182.png in 0.11186504 s\n",
      "predicted dataset/test/test1/Tile_0183.png in 0.05629849 s\n",
      "predicted dataset/test/test1/Tile_0184.png in 0.16664386 s\n",
      "predicted dataset/test/test1/Tile_0185.png in 0.21764803 s\n",
      "predicted dataset/test/test1/Tile_0186.png in 0.07592940 s\n",
      "predicted dataset/test/test1/Tile_0187.png in 0.08781195 s\n",
      "predicted dataset/test/test1/Tile_0188.png in 0.16401911 s\n",
      "predicted dataset/test/test1/Tile_0189.png in 0.04231119 s\n",
      "predicted dataset/test/test1/Tile_0190.png in 0.04708576 s\n",
      "predicted dataset/test/test1/Tile_0191.png in 0.07935023 s\n",
      "predicted dataset/test/test1/Tile_0192.png in 0.07249594 s\n",
      "predicted dataset/test/test1/Tile_0193.png in 0.03481674 s\n",
      "predicted dataset/test/test1/Tile_0194.png in 0.05075526 s\n",
      "predicted dataset/test/test1/Tile_0195.png in 0.07875919 s\n",
      "predicted dataset/test/test1/Tile_0196.png in 0.04981375 s\n",
      "predicted dataset/test/test1/Tile_0197.png in 0.04085422 s\n",
      "predicted dataset/test/test1/Tile_0198.png in 0.09371877 s\n",
      "predicted dataset/test/test1/Tile_0199.png in 0.04683948 s\n",
      "predicted dataset/test/test1/Tile_0200.png in 0.03551173 s\n",
      "predicted dataset/test/test1/Tile_0201.png in 0.03406286 s\n",
      "predicted dataset/test/test1/Tile_0202.png in 0.03484750 s\n",
      "predicted dataset/test/test1/Tile_0203.png in 0.03472090 s\n",
      "predicted dataset/test/test1/Tile_0204.png in 0.03354383 s\n",
      "predicted dataset/test/test1/Tile_0205.png in 0.04128766 s\n",
      "predicted dataset/test/test1/Tile_0206.png in 0.03367472 s\n",
      "predicted dataset/test/test1/Tile_0207.png in 0.03519940 s\n",
      "predicted dataset/test/test1/Tile_0208.png in 0.03396821 s\n",
      "predicted dataset/test/test1/Tile_0209.png in 0.03310943 s\n",
      "predicted dataset/test/test1/Tile_0210.png in 0.03271008 s\n",
      "predicted dataset/test/test1/Tile_0211.png in 0.03768754 s\n",
      "predicted dataset/test/test1/Tile_0212.png in 0.03306627 s\n",
      "predicted dataset/test/test1/Tile_0213.png in 0.03259373 s\n",
      "predicted dataset/test/test1/Tile_0214.png in 0.03782320 s\n",
      "predicted dataset/test/test1/Tile_0215.png in 0.03288913 s\n",
      "predicted dataset/test/test1/Tile_0216.png in 0.03215480 s\n",
      "predicted dataset/test/test1/Tile_0217.png in 0.03554296 s\n",
      "predicted dataset/test/test1/Tile_0218.png in 0.03363347 s\n",
      "predicted dataset/test/test1/Tile_0219.png in 0.03157949 s\n",
      "predicted dataset/test/test1/Tile_0220.png in 0.03267193 s\n",
      "predicted dataset/test/test1/Tile_0221.png in 0.03164363 s\n",
      "predicted dataset/test/test1/Tile_0222.png in 0.03609753 s\n",
      "predicted dataset/test/test1/Tile_0223.png in 0.03575659 s\n",
      "predicted dataset/test/test1/Tile_0224.png in 0.03330159 s\n",
      "predicted dataset/test/test1/Tile_0225.png in 0.03128743 s\n",
      "predicted dataset/test/test1/Tile_0226.png in 0.03200841 s\n",
      "predicted dataset/test/test1/Tile_0227.png in 0.03133106 s\n",
      "predicted dataset/test/test1/Tile_0228.png in 0.03125763 s\n",
      "predicted dataset/test/test1/Tile_0229.png in 0.03157687 s\n",
      "predicted dataset/test/test1/Tile_0230.png in 0.03321075 s\n",
      "predicted dataset/test/test1/Tile_0231.png in 0.03626156 s\n",
      "predicted dataset/test/test1/Tile_0232.png in 0.03149652 s\n",
      "predicted dataset/test/test1/Tile_0233.png in 0.03127575 s\n",
      "predicted dataset/test/test1/Tile_0234.png in 0.03110671 s\n",
      "predicted dataset/test/test1/Tile_0235.png in 0.03334856 s\n",
      "predicted dataset/test/test1/Tile_0236.png in 0.03754735 s\n",
      "predicted dataset/test/test1/Tile_0237.png in 0.03334022 s\n",
      "predicted dataset/test/test1/Tile_0238.png in 0.03310537 s\n",
      "predicted dataset/test/test1/Tile_0239.png in 0.03394079 s\n",
      "predicted dataset/test/test1/Tile_0240.png in 0.03877282 s\n",
      "predicted dataset/test/test1/Tile_0241.png in 0.04015899 s\n",
      "predicted dataset/test/test1/Tile_0242.png in 0.03439140 s\n",
      "predicted dataset/test/test1/Tile_0243.png in 0.03344131 s\n",
      "predicted dataset/test/test1/Tile_0244.png in 0.03220177 s\n",
      "predicted dataset/test/test1/Tile_0245.png in 0.03579450 s\n",
      "predicted dataset/test/test1/Tile_0246.png in 0.03321528 s\n",
      "predicted dataset/test/test1/Tile_0247.png in 0.03635788 s\n",
      "predicted dataset/test/test1/Tile_0248.png in 0.03653812 s\n",
      "predicted dataset/test/test1/Tile_0249.png in 0.03364110 s\n",
      "predicted dataset/test/test1/Tile_0250.png in 0.03354383 s\n",
      "predicted dataset/test/test1/Tile_0251.png in 0.03374171 s\n",
      "predicted dataset/test/test1/Tile_0252.png in 0.03332567 s\n",
      "predicted dataset/test/test1/Tile_0253.png in 0.03537321 s\n",
      "predicted dataset/test/test1/Tile_0254.png in 0.03213954 s\n",
      "predicted dataset/test/test1/Tile_0255.png in 0.03369951 s\n",
      "predicted dataset/test/test1/Tile_0256.png in 0.03234696 s\n",
      "predicted dataset/test/test1/Tile_0257.png in 0.03844380 s\n",
      "predicted dataset/test/test1/Tile_0258.png in 0.03448606 s\n",
      "predicted dataset/test/test1/Tile_0259.png in 0.03371501 s\n",
      "predicted dataset/test/test1/Tile_0260.png in 0.03477883 s\n",
      "predicted dataset/test/test1/Tile_0261.png in 0.03577423 s\n",
      "predicted dataset/test/test1/Tile_0262.png in 0.03294206 s\n",
      "predicted dataset/test/test1/Tile_0263.png in 0.03785706 s\n",
      "predicted dataset/test/test1/Tile_0264.png in 0.03901172 s\n",
      "predicted dataset/test/test1/Tile_0265.png in 0.04005933 s\n",
      "predicted dataset/test/test1/Tile_0266.png in 0.04124784 s\n",
      "predicted dataset/test/test1/Tile_0267.png in 0.03874493 s\n",
      "predicted dataset/test/test1/Tile_0268.png in 0.05561876 s\n",
      "predicted dataset/test/test1/Tile_0269.png in 0.05501199 s\n",
      "predicted dataset/test/test1/Tile_0270.png in 0.04645348 s\n",
      "predicted dataset/test/test1/Tile_0271.png in 0.04410100 s\n",
      "predicted dataset/test/test1/Tile_0272.png in 0.03983545 s\n",
      "predicted dataset/test/test1/Tile_0273.png in 0.03834462 s\n",
      "predicted dataset/test/test1/Tile_0274.png in 0.04531193 s\n",
      "predicted dataset/test/test1/Tile_0275.png in 0.16331935 s\n",
      "predicted dataset/test/test1/Tile_0276.png in 0.04201269 s\n",
      "predicted dataset/test/test1/Tile_0277.png in 0.03929448 s\n",
      "predicted dataset/test/test1/Tile_0278.png in 0.03686452 s\n",
      "predicted dataset/test/test1/Tile_0279.png in 0.03768229 s\n",
      "predicted dataset/test/test1/Tile_0280.png in 0.03749776 s\n",
      "predicted dataset/test/test1/Tile_0281.png in 0.04240465 s\n",
      "predicted dataset/test/test1/Tile_0282.png in 0.04337931 s\n",
      "predicted dataset/test/test1/Tile_0283.png in 0.04336834 s\n",
      "predicted dataset/test/test1/Tile_0284.png in 0.03947806 s\n",
      "predicted dataset/test/test1/Tile_0285.png in 0.03950429 s\n",
      "predicted dataset/test/test1/Tile_0286.png in 0.03995800 s\n",
      "predicted dataset/test/test1/Tile_0287.png in 0.04343915 s\n",
      "predicted dataset/test/test1/Tile_0288.png in 0.04384708 s\n",
      "predicted dataset/test/test1/Tile_0289.png in 0.04533005 s\n",
      "predicted dataset/test/test1/Tile_0290.png in 0.04439163 s\n",
      "predicted dataset/test/test1/Tile_0291.png in 0.04750967 s\n",
      "predicted dataset/test/test1/Tile_0292.png in 0.04935837 s\n",
      "predicted dataset/test/test1/Tile_0293.png in 0.04680991 s\n",
      "predicted dataset/test/test1/Tile_0294.png in 0.04539132 s\n",
      "predicted dataset/test/test1/Tile_0295.png in 0.04426694 s\n",
      "predicted dataset/test/test1/Tile_0296.png in 0.04646420 s\n",
      "predicted dataset/test/test1/Tile_0297.png in 0.04317904 s\n",
      "predicted dataset/test/test1/Tile_0298.png in 0.04496074 s\n",
      "predicted dataset/test/test1/Tile_0299.png in 0.04345536 s\n",
      "predicted dataset/test/test1/Tile_0300.png in 0.04443502 s\n",
      "predicted dataset/test/test1/Tile_0301.png in 0.05228734 s\n",
      "predicted dataset/test/test1/Tile_0302.png in 0.04848862 s\n",
      "predicted dataset/test/test1/Tile_0303.png in 0.05804205 s\n",
      "predicted dataset/test/test1/Tile_0304.png in 0.06708288 s\n",
      "predicted dataset/test/test1/Tile_0305.png in 0.04970360 s\n",
      "predicted dataset/test/test1/Tile_0306.png in 0.04418707 s\n",
      "predicted dataset/test/test1/Tile_0307.png in 0.18032718 s\n",
      "predicted dataset/test/test1/Tile_0308.png in 0.06153154 s\n",
      "predicted dataset/test/test1/Tile_0309.png in 0.05069184 s\n",
      "predicted dataset/test/test1/Tile_0310.png in 0.05428147 s\n",
      "predicted dataset/test/test1/Tile_0311.png in 0.04023600 s\n",
      "predicted dataset/test/test1/Tile_0312.png in 0.04311371 s\n",
      "predicted dataset/test/test1/Tile_0313.png in 0.04863501 s\n",
      "predicted dataset/test/test1/Tile_0314.png in 0.04007387 s\n",
      "predicted dataset/test/test1/Tile_0315.png in 0.03625774 s\n",
      "predicted dataset/test/test1/Tile_0316.png in 0.03941917 s\n",
      "predicted dataset/test/test1/Tile_0317.png in 0.04038119 s\n",
      "predicted dataset/test/test1/Tile_0318.png in 0.04498005 s\n",
      "predicted dataset/test/test1/Tile_0319.png in 0.03900266 s\n",
      "predicted dataset/test/test1/Tile_0320.png in 0.04318237 s\n",
      "predicted dataset/test/test1/Tile_0321.png in 0.04064131 s\n",
      "predicted dataset/test/test1/Tile_0322.png in 0.04160452 s\n",
      "predicted dataset/test/test1/Tile_0323.png in 0.03938794 s\n",
      "predicted dataset/test/test1/Tile_0324.png in 0.03631473 s\n",
      "predicted dataset/test/test1/Tile_0325.png in 0.03988051 s\n",
      "predicted dataset/test/test1/Tile_0326.png in 0.03708148 s\n",
      "predicted dataset/test/test1/Tile_0327.png in 0.04500175 s\n",
      "predicted dataset/test/test1/Tile_0328.png in 0.03674507 s\n",
      "predicted dataset/test/test1/Tile_0329.png in 0.03638577 s\n",
      "predicted dataset/test/test1/Tile_0330.png in 0.03698611 s\n",
      "predicted dataset/test/test1/Tile_0331.png in 0.03591180 s\n",
      "predicted dataset/test/test1/Tile_0332.png in 0.04192090 s\n",
      "predicted dataset/test/test1/Tile_0333.png in 0.03960204 s\n",
      "predicted dataset/test/test1/Tile_0334.png in 0.03907251 s\n",
      "predicted dataset/test/test1/Tile_0335.png in 0.04431629 s\n",
      "predicted dataset/test/test1/Tile_0336.png in 0.04581857 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "from tiled_detiled import tiled_image\n",
    "import time\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "sensitivty = 0.5\n",
    "target_f = \"dataset/raw/labeled/10m/DJI_0016.JPG\"\n",
    "\n",
    "if len(os.listdir('dataset/test/test1')) != 0:\n",
    "    print(\"Found previous tiled images, attemp delete\")\n",
    "    file_to_delete = os.listdir('dataset/test/test1')\n",
    "    for f in file_to_delete:\n",
    "        os.remove('dataset/test/test1/' + f)\n",
    "\n",
    "target_im = cv2.imread(target_f)\n",
    "#save otuput\n",
    "from glob import glob\n",
    "import math\n",
    "result_heigth = target_im.shape[0]\n",
    "result_width = target_im.shape[1]\n",
    "tile_size = 256\n",
    "\n",
    "if target_im is not None:\n",
    "    tiled_image(target_im, 256, \"dataset/test/test1\")\n",
    "else:\n",
    "    print(\"Cannot read ifle\")\n",
    "\n",
    "\n",
    "#Slice image\n",
    "predict_file = sorted(glob(\"dataset/test/test1/*.png\"))\n",
    "predict_file = iter(predict_file)\n",
    "# print(predict_file)\n",
    "\n",
    "predicted_list = []\n",
    "\n",
    "#remove existing file\n",
    "if len(os.listdir('dataset/test/result_test1')) != 0:\n",
    "    print(\"Found previous predicted files, attemp delete\")\n",
    "    file_to_delete = os.listdir('dataset/test/result_test1')\n",
    "    for f in file_to_delete:\n",
    "        os.remove('dataset/test/result_test1/' + f)\n",
    "#predict slided image\n",
    "nn = 1\n",
    "for f in predict_file:\n",
    "    target = f\n",
    "    # print(target)\n",
    "    inputs = cv2.imread(target)\n",
    "    tic = time.time()\n",
    "    r = predict_tile(inputs, sensitivity)\n",
    "    toc = time.time()\n",
    "    print(\"predicted %s in %.8f s\" %(f, toc - tic))\n",
    "    tf.keras.preprocessing.image.save_img('dataset/test/result_test1/result_%s.png'% str(nn).zfill(4),r)\n",
    "    nn += 1\n",
    "\n",
    "\n",
    "\n",
    "file = sorted(glob(\"dataset/test/result_test1/*\"))\n",
    "\n",
    "temp = np.zeros((math.ceil(result_heigth / tile_size) * tile_size, math.ceil(result_width / tile_size) * tile_size,3))\n",
    "\n",
    "i = 0\n",
    "for r in range(0, temp.shape[0], tile_size):\n",
    "    for c in range(0, temp.shape[1], tile_size):\n",
    "        tile = cv2.imread(file[i])\n",
    "        temp[r:r + tile_size, c:c + tile_size,:] = tile \n",
    "        i += 1\n",
    "\n",
    "cv2.imwrite(\"predicted_location.jpg\" , temp[:result_heigth, :5274,:])\n",
    "# cv2.imwrite(\"predicted_location_DJI_20211208095147_0040.JPG\" , temp[:5460, :8192,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3956, 5274, 3) (3956, 5274, 3)\n",
      "IoU socre is:  0.17567833865594257\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def convert_bw(img):\n",
    "    grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    bw = cv2.threshold(grayImage, 128, 255, cv2.THRESH_BINARY)[1]\n",
    "    image_bw = Image.fromarray(bw)\n",
    "    return image_bw\n",
    "\n",
    "_ground_truth = cv2.imread('DJI_0007_mask.jpg')\n",
    "_pred = cv2.imread(\"predicted_location.jpg\")\n",
    "gt = convert_bw(_ground_truth)\n",
    "pd = convert_bw(_pred)\n",
    "\n",
    "print(_ground_truth.shape, _pred.shape)\n",
    "intersection = np.logical_and(gt, pd)\n",
    "union = np.logical_or(gt, pd)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8fcb75110a54a95449da3edd6bc4968834d7697970658473e67a56856224e4f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cv_asagau': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
