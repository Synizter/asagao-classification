{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import normalize\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = []\n",
    "msk_dataset = []\n",
    "\n",
    "f_img = sorted(glob('dataset/train/asagao/*'))\n",
    "for f in f_img:\n",
    "    image = cv2.imread(f)\n",
    "    # image = image.resize((SIZE, SIZE))\n",
    "    #Nomalize an image from 0-255 to 0 - 1\n",
    "    image = image.astype('float32') / 255.0\n",
    "    img_dataset.append(np.array(image))\n",
    "\n",
    "f_msk = sorted(glob('dataset/validation/asagao/*'))\n",
    "for f in f_msk:\n",
    "    image = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "    (thresh, im_bw) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    image = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    # image = Image.fromarray(image)\n",
    "    # image = image.resize((SIZE, SIZE))\n",
    "    msk_dataset.append(np.array(image))\n",
    "\n",
    "# img_dataset = (img_dataset - v_min)/(v_max - v_min)\n",
    "# print(img_dataset.shape)\n",
    "# #Normalize images\n",
    "# img_dataset = normalize(np.array(img_dataset), axis=1) #wrong normalization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "asagao_dataset = np.array(img_dataset)\n",
    "# img_dataset = np.array(img_dataset)\n",
    "# #D not normalize masks, just rescale to 0 to 1.a\n",
    "asagao_msk_dataset = np.expand_dims(np.array(msk_dataset) /255., -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X_train, X_test, y_train, y_test = train_test_split(asagao_dataset, asagao_msk_dataset, test_size= 0.10, random_state=0)\n",
    "# y_train = to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# X_train_quick_test, X_test_quick_test, y_train_quick_test, y_test_quick_test = train_test_split(X_train, y_train, test_size = 0.9, random_state = 0)\n",
    "# image_number = random.randint(0, len(X_train_quick_test))\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(np.reshape(X_train_quick_test[image_number], (256, 256,3)))\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(np.reshape(y_train_quick_test[image_number], (256, 256,1)), cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 16) 448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256, 256, 16) 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 16) 2320        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 32) 4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128, 128, 32) 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 32) 9248        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64, 64, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 64)   36928       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 128)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 128)  147584      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 256)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 256)  590080      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 128)  295040      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 256)  0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 128)  0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 128)  147584      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64, 64, 64)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   36928       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 128, 128, 32) 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 128, 128, 32) 9248        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 16) 2064        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256, 256, 16) 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 256, 256, 16) 2320        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 256, 256, 1)  17          conv2d_36[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,104,945\n",
      "Trainable params: 2,104,945\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout,Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "# model.summary()\n",
    "input_w = 256\n",
    "input_h = 256\n",
    "input_ch = 3\n",
    "\n",
    "s  = Input((input_w, input_h, input_ch))\n",
    "#Downscale path -----------------------------------------------------------------------------------\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = Dropout(0.1)(c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = MaxPooling2D((2, 2))(c1)\n",
    "#100\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = Dropout(0.1)(c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = MaxPooling2D((2, 2))(c2)\n",
    "#50\n",
    "c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = Dropout(0.2)(c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = MaxPooling2D((2, 2))(c3)\n",
    "#15\n",
    "c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = Dropout(0.2)(c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    \n",
    "c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = Dropout(0.3)(c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "#Scale up path ----------------------------------------------------------------------------------\n",
    "u6 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = Dropout(0.2)(c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "    \n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = Dropout(0.2)(c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "    \n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = Dropout(0.1)(c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "    \n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = Dropout(0.1)(c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    \n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "model = Model(inputs=[s], outputs=[outputs])\n",
    "opt = Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with asagao pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor = 'val_loss', verbose = 1)\n",
    "mc  = ModelCheckpoint(\"50-30mUnet.h5\", monitor = \"val_loss\", save_best_only = True)\n",
    "\n",
    "callback_list = [es, mc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_previous = history\n",
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    verbose = 1,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 100,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    shuffle = False)\n",
    "model.save(\"50m_30m_Unet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = history_previous\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training acc',linewidth=2)\n",
    "plt.plot(epochs, val_acc, 'r--', label='Validation acc',linewidth=2)\n",
    "plt.title('Training  accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "\n",
    "plt.plot(epochs, val_loss, 'k', label='Validationloss ')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.6\n",
    "\n",
    "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
    "union = np.logical_or(y_test, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with non-asagao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_asagao_dataset = []\n",
    "# non_asagao_msk_dataset = []\n",
    "\n",
    "# f_img = sorted(glob('dataset/non_asagao_train/*'))\n",
    "# for f in f_img:\n",
    "#     image = cv2.imread(f)\n",
    "#     # image = image.resize((SIZE, SIZE))\n",
    "#     #Nomalize an image from 0-255 to 0 - 1\n",
    "#     image = image.astype('float32') / 255.0\n",
    "#     img_dataset.append(np.array(image))\n",
    "\n",
    "# f_msk = sorted(glob('dataset/non_asagao_validation/*'))\n",
    "# for f in f_msk:\n",
    "#     image = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "#     (thresh, im_bw) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#     image = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "#     # image = Image.fromarray(image)\n",
    "#     # image = image.resize((SIZE, SIZE))\n",
    "#     msk_dataset.append(np.array(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_asagao_dataset = np.array(img_dataset)\n",
    "# # img_dataset = np.array(img_dataset)\n",
    "# # #D not normalize masks, just rescale to 0 to 1.a\n",
    "# non_asagao_msk_dataset = np.expand_dims(np.array(msk_dataset) /255., -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# X_train, X_test, y_train, y_test = train_test_split(non_asagao_dataset, non_asagao_msk_dataset, test_size= 0.20, random_state=0)\n",
    "# y_train = to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, \n",
    "#                     y_train,\n",
    "#                     verbose = 1,\n",
    "#                     batch_size = 16,\n",
    "#                     epochs = 50,\n",
    "#                     validation_data = (X_test, y_test),\n",
    "#                     shuffle = False)\n",
    "# model.save(\"50m_30m_Unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# val_loss = history.history['val_loss']\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs, acc, 'b', label='Training acc',linewidth=2)\n",
    "# plt.plot(epochs, val_acc, 'r--', label='Validation acc',linewidth=2)\n",
    "# plt.title('Training  accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "\n",
    "# plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "\n",
    "# plt.plot(epochs, val_loss, 'k', label='Validationloss ')\n",
    "# plt.title('Training loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################\n",
    "# #IOU\n",
    "# y_pred=model.predict(X_test)\n",
    "# y_pred_thresholded = y_pred > 0.6\n",
    "\n",
    "# intersection = np.logical_and(y_test, y_pred_thresholded)\n",
    "# union = np.logical_or(y_test, y_pred_thresholded)\n",
    "# iou_score = np.sum(intersection) / np.sum(union)\n",
    "# print(\"IoU socre is: \", iou_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test within known data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tile(tile, sens = 0.001):\n",
    "    tile = tile.astype('float32') / 255.0\n",
    "    test_img_other_input=np.expand_dims(tile, 0)\n",
    "    prob_map = (model.predict(test_img_other_input) > sensitivty).astype(np.uint8)\n",
    "    return prob_map[0]\n",
    "    \n",
    "\n",
    "file_name = \"asagao_0001.png\"\n",
    "train_file = 'dataset/train/asagao/' + file_name\n",
    "test_file = 'dataset/validation/asagao/' + file_name.replace(\"asagao_\", \"asagao_mask_\" )\n",
    "\n",
    "print(train_file, test_file)\n",
    "sensitivty = 0.4\n",
    "test_img_other = cv2.imread(train_file)\n",
    "r = predict_tile(test_img_other, sensitivty)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "actual = cv2.imread(train_file)\n",
    "mask = cv2.imread(test_file)\n",
    "plt.subplot(131),plt.imshow(actual),plt.title(\"Actual\")\n",
    "plt.subplot(132),plt.imshow(mask),plt.title(\"Actual mask\")\n",
    "plt.subplot(133),plt.imshow(r, cmap=\"gray\"),plt.title(\"Prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with tiled image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.Slice the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from tiled_detiled import tiled_image\n",
    "import time\n",
    "\n",
    "sensitivity = 0.6\n",
    "target_f = \"dataset/test/DJI_20211208095147_0040.JPG\"\n",
    "\n",
    "if len(os.listdir('dataset/test/test1')) != 0:\n",
    "    print(\"Found previous tiled images, attemp delete\")\n",
    "    file_to_delete = os.listdir('dataset/test/test1')\n",
    "    for f in file_to_delete:\n",
    "        os.remove('dataset/test/test1/' + f)\n",
    "\n",
    "target_im = cv2.imread(target_f)\n",
    "if target_im is not None:\n",
    "    tiled_image(target_im, 256, \"dataset/test/test1\")\n",
    "else:\n",
    "    print(\"Cannot read ifle\")\n",
    "\n",
    "\n",
    "#Slice image\n",
    "predict_file = sorted(glob(\"dataset/test/test1/*.png\"))\n",
    "predict_file = iter(predict_file)\n",
    "# print(predict_file)\n",
    "\n",
    "predicted_list = []\n",
    "\n",
    "#remove existing file\n",
    "if len(os.listdir('dataset/test/result_test1')) != 0:\n",
    "    print(\"Found previous predicted files, attemp delete\")\n",
    "    file_to_delete = os.listdir('dataset/test/result_test1')\n",
    "    for f in file_to_delete:\n",
    "        os.remove('dataset/test/result_test1/' + f)\n",
    "#predict slided image\n",
    "nn = 1\n",
    "for f in predict_file:\n",
    "    target = f\n",
    "    # print(target)\n",
    "    inputs = cv2.imread(target)\n",
    "    tic = time.time()\n",
    "    r = predict_tile(inputs, sensitivity)\n",
    "    toc = time.time()\n",
    "    print(\"predicted %s in %.8f s\" %(f, toc - tic))\n",
    "    tf.keras.preprocessing.image.save_img('dataset/test/result_test1/result_%s.png'% str(nn).zfill(4),r)\n",
    "    nn += 1\n",
    "\n",
    "#save otuput\n",
    "from glob import glob\n",
    "import math\n",
    "result_heigth = 5460\n",
    "result_width = 8192\n",
    "tile_size = 256\n",
    "\n",
    "\n",
    "file = sorted(glob(\"dataset/test/result_test1/*\"))\n",
    "\n",
    "temp = np.zeros((math.ceil(result_heigth / tile_size) * tile_size, math.ceil(result_width / tile_size) * tile_size,3))\n",
    "\n",
    "i = 0\n",
    "for r in range(0, temp.shape[0], tile_size):\n",
    "    for c in range(0, temp.shape[1], tile_size):\n",
    "        tile = cv2.imread(file[i])\n",
    "        temp[r:r + tile_size, c:c + tile_size,:] = tile \n",
    "        i += 1\n",
    "\n",
    "cv2.imwrite(\"predicted_location.jpg\" , temp[:5460, :8192,:])\n",
    "# cv2.imwrite(\"predicted_location_DJI_20211208095147_0040.JPG\" , temp[:5460, :8192,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bw(img):\n",
    "    grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    bw = cv2.threshold(grayImage, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    image_bw = Image.fromarray(bw)\n",
    "    return image_bw\n",
    "\n",
    "_ground_truth = cv2.imread('DJI_20211208095147_0040_mask.jpg')\n",
    "_pred = cv2.imread(\"predicted_location_0040.jpg\")\n",
    "\n",
    "gt = convert_bw(_ground_truth)\n",
    "pd = convert_bw(_pred)\n",
    "\n",
    "\n",
    "intersection = np.logical_and(gt, pd)\n",
    "union = np.logical_or(gt, pd)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8fcb75110a54a95449da3edd6bc4968834d7697970658473e67a56856224e4f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cv_asagau': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
