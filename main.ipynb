{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 16:19:37.450867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import normalize\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "astype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18481/967026226.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Nomalize an image from 0-255 to 0 - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mimg_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cv_asagau/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    544\u001b[0m             )\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: astype"
     ]
    }
   ],
   "source": [
    "img_dataset = []\n",
    "msk_dataset = []\n",
    "\n",
    "f_img = sorted(glob('dataset/train/*'))\n",
    "for f in f_img:\n",
    "    image = cv2.imread(f)\n",
    "    image = Image.fromarray(image)\n",
    "    # image = image.resize((SIZE, SIZE))\n",
    "\n",
    "    #Nomalize an image from 0-255 to 0 - 1\n",
    "    image = image.astype('float32') / 255.0\n",
    "    img_dataset.append(np.array(image))\n",
    "\n",
    "f_msk = sorted(glob('dataset/validation/*'))\n",
    "for f in f_msk:\n",
    "    image = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "    (thresh, im_bw) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    image = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    image = Image.fromarray(image)\n",
    "    # image = image.resize((SIZE, SIZE))\n",
    "    msk_dataset.append(np.array(image))\n",
    "\n",
    "# img_dataset = (img_dataset - v_min)/(v_max - v_min)\n",
    "# print(img_dataset.shape)\n",
    "# #Normalize images\n",
    "# img_dataset = normalize(np.array(img_dataset), axis=1) #wrong normalization\n",
    "\n",
    "\n",
    "\n",
    "# img_dataset = np.array(img_dataset)\n",
    "# #D not normalize masks, just rescale to 0 to 1.\n",
    "msk_dataset = np.expand_dims(np.array(msk_dataset) /255., -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_dataset, msk_dataset, test_size= 0.15, random_state=0)\n",
    "# y_train = to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "X_train_quick_test, X_test_quick_test, y_train_quick_test, y_test_quick_test = train_test_split(X_train, y_train, test_size = 0.9, random_state = 0)\n",
    "image_number = random.randint(0, len(X_train_quick_test))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(X_train_quick_test[image_number], (256, 256,3)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(y_train_quick_test[image_number], (256, 256,1)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout,Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "# model.summary()\n",
    "nbr_data = img_dataset.shape[0]\n",
    "input_w = 256\n",
    "input_h = 256\n",
    "input_ch = 3\n",
    "\n",
    "s  = Input((input_w, input_h, input_ch))\n",
    "#Downscale path -----------------------------------------------------------------------------------\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = Dropout(0.1)(c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = MaxPooling2D((2, 2))(c1)\n",
    "#100\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = Dropout(0.1)(c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = MaxPooling2D((2, 2))(c2)\n",
    "#50\n",
    "c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = Dropout(0.2)(c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = MaxPooling2D((2, 2))(c3)\n",
    "#15\n",
    "c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = Dropout(0.2)(c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    \n",
    "c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = Dropout(0.3)(c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "#Scale up path ----------------------------------------------------------------------------------\n",
    "u6 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = Dropout(0.2)(c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "    \n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = Dropout(0.2)(c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "    \n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = Dropout(0.1)(c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "    \n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = Dropout(0.1)(c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    \n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "model = Model(inputs=[s], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    verbose = 1,\n",
    "                    batch_size = 16,\n",
    "                    epochs = 65,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    shuffle = False)\n",
    "model.save(\"50m_30m_Unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training acc',linewidth=2)\n",
    "plt.plot(epochs, val_acc, 'r--', label='Validation acc',linewidth=2)\n",
    "plt.title('Training  accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "\n",
    "plt.plot(epochs, val_loss, 'k', label='Validationloss ')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.5\n",
    "\n",
    "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
    "union = np.logical_or(y_test, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test within known data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train file name\n",
    "file_name = \"asagao_0013.png\"\n",
    "train_file = 'dataset/train/' + file_name\n",
    "test_file = 'dataset/validation/' + file_name.replace(\"asagao_\", \"asagao_mask_\" )\n",
    "\n",
    "test_img_other = cv2.imread(train_file)\n",
    "\n",
    "test_img_other_norm = normalize(np.array(test_img_other), axis=1)\n",
    "test_img_other_input = test_img_other_norm\n",
    "test_img_other_input=np.expand_dims(test_img_other_norm, 0)\n",
    "\n",
    "\n",
    "prediction_other = (model.predict(test_img_other_input) > 0.6).astype(np.uint8)\n",
    "plt.figure(figsize=(20,20))\n",
    "actual = cv2.imread(train_file)\n",
    "mask = cv2.imread(test_file)\n",
    "plt.subplot(131),plt.imshow(actual),plt.title(\"Actual\")\n",
    "plt.subplot(132),plt.imshow(mask),plt.title(\"Actual mask\")\n",
    "plt.subplot(133),plt.imshow(prediction_other[0], cmap=\"gray\"),plt.title(\"Prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with tiled image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.Slice the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "from tiled_detiled import tiled_image\n",
    "\n",
    "\n",
    "target_f = \"dataset/test/DJI_20211208095147_0040.JPG\"\n",
    "\n",
    "if len(os.listdir('dataset/test/test1')) != 0:\n",
    "    print(\"Found previous dataset, attemp delete\")\n",
    "    file_to_delete = os.listdir('dataset/test/test1')\n",
    "    for f in file_to_delete:\n",
    "        os.remove('dataset/test/test1/' + f)\n",
    "\n",
    "target_im = cv2.imread(target_f)\n",
    "if target_im is not None:\n",
    "    tiled_image(target_im, 256, \"dataset/test/test1\")\n",
    "else:\n",
    "    print(\"Cannot read ifle\")\n",
    "\n",
    "\n",
    "#Slice image\n",
    "predict_file = sorted(glob(\"dataset/test/test1/*.png\"))\n",
    "predict_file = iter(predict_file)\n",
    "# print(predict_file)\n",
    "\n",
    "predicted_list = []\n",
    "\n",
    "#remove existing file\n",
    "if len(os.listdir('dataset/test/result_test1')) != 0:\n",
    "    print(\"Found previous dataset, attemp delete\")\n",
    "    file_to_delete = os.listdir('dataset/test/result_test1')\n",
    "    for f in file_to_delete:\n",
    "        os.remove('dataset/test/result_test1/' + f)\n",
    "#predict slided image\n",
    "nn = 1\n",
    "for f in predict_file:\n",
    "    target = f\n",
    "    # print(target)\n",
    "    test_img_other = cv2.imread(target)\n",
    "    test_img_other_norm = normalize(np.array(test_img_other), axis=1)\n",
    "    test_img_other_input = test_img_other_norm\n",
    "    test_img_other_input=np.expand_dims(test_img_other_norm, 0)\n",
    "    prediction_other = (model.predict(test_img_other_input) > 0.4).astype(np.uint8)\n",
    "    tf.keras.preprocessing.image.save_img('dataset/test/result_test1/result_%s.png'% str(nn).zfill(4),prediction_other[0])\n",
    "    nn += 1\n",
    "\n",
    "#save otuput\n",
    "from glob import glob\n",
    "import math\n",
    "result_heigth = 5460\n",
    "result_width = 8192\n",
    "tile_size = 256\n",
    "\n",
    "\n",
    "file = sorted(glob(\"dataset/test/result_test1/*\"))\n",
    "\n",
    "temp = np.zeros((math.ceil(result_heigth / tile_size) * tile_size, math.ceil(result_width / tile_size) * tile_size,3))\n",
    "\n",
    "i = 0\n",
    "for r in range(0, temp.shape[0], tile_size):\n",
    "    for c in range(0, temp.shape[1], tile_size):\n",
    "        tile = cv2.imread(file[i])\n",
    "        temp[r:r + tile_size, c:c + tile_size,:] = tile \n",
    "        i += 1\n",
    "\n",
    "# cv2.imwrite(\"predicted_location_\" + target_f[-35:] , temp[:5460, :8192,:])\n",
    "cv2.imwrite(\"predicted_location_DJI_20211208095147_0040.JPG\" , temp[:5460, :8192,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Keep predict each tiles then patch each tile into one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(len(file)):\n",
    "#     #read image\n",
    "#     tile = cv2.imread(file[i])\n",
    "#     if(i == 4): #move to next row\n",
    "#         row += tile.shape[0]\n",
    "#         col = 0\n",
    "#     temp[row:row + tile.shape[0], col:col + tile.shape[1],:] = tile\n",
    "#     col += tile.shape[1]\n",
    "#     # stride += tile.shape[0]\n",
    "\n",
    "# except Exception as e:\n",
    "# #     print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Intersect over union calculation\n",
    "IoU = overlaps_area / union area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bw(img):\n",
    "    grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    bw = cv2.threshold(grayImage, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    image_bw = Image.fromarray(bw)\n",
    "    return image_bw\n",
    "\n",
    "_ground_truth = cv2.imread(\"actual_location_DJI_20211208095147_0040_LABELED.jpg\")\n",
    "_pred = cv2.imread(\"predicted_location_DJI_20211208095147_0040.JPG\")\n",
    "\n",
    "gt = convert_bw(_ground_truth)\n",
    "pd = convert_bw(_pred)\n",
    "\n",
    "\n",
    "intersection = np.logical_and(gt, pd)\n",
    "union = np.logical_or(gt, pd)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\"IoU socre is: \", iou_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8fcb75110a54a95449da3edd6bc4968834d7697970658473e67a56856224e4f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cv_asagau': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
